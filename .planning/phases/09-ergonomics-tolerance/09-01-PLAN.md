---
phase: 09-ergonomics-tolerance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tools_extract.py
  - src/tool_errors.py
  - src/tools_write.py
  - tests/test_ergonomics.py
autonomous: true
requirements:
  - ERG-01
  - ERG-02
  - TOL-01
  - TOL-02

must_haves:
  truths:
    - "extract_structure_compact response includes file_path when agent provides file_path input"
    - "extract_structure_compact response does NOT include file_path when agent uses file_bytes_b64"
    - "write_answers error for missing file mentions extract_structure_compact by name"
    - "answer_text='SKIP' (case-insensitive) causes no write and status='skipped' in response"
    - "write_answers response always includes a summary dict with written and skipped counts"
    - "All-SKIP edge case returns original file bytes unchanged"
    - "dry_run shows SKIP answers with status='skipped'"
  artifacts:
    - path: "src/tools_extract.py"
      provides: "file_path echo in extract_structure_compact response"
      contains: "result[\"file_path\"]"
    - path: "src/tool_errors.py"
      provides: "write_answers-specific error message"
      contains: "Missing file_path -- this is the path you passed to extract_structure_compact"
    - path: "src/tools_write.py"
      provides: "SKIP detection, filtering, summary in response"
      contains: "_is_skip"
    - path: "tests/test_ergonomics.py"
      provides: "Tests for all four requirements"
      min_lines: 80
  key_links:
    - from: "src/tools_extract.py"
      to: "extract_structure_compact response dict"
      via: "dict injection after model_dump()"
      pattern: "result\\[.file_path.\\]"
    - from: "src/tool_errors.py"
      to: "validators.py resolve_file_input"
      via: "catch ValueError, check tool_name == write_answers"
      pattern: "write_answers.*Neither was supplied"
    - from: "src/tools_write.py"
      to: "tool_errors.py build_answer_payloads"
      via: "SKIP filtering after payload construction"
      pattern: "_is_skip"
---

<objective>
Implement four ergonomics and tolerance improvements to reduce agent friction: echo file_path in extract_structure_compact responses, improve write_answers error messages, support SKIP sentinel for intentionally blank fields, and add summary counts to write_answers responses.

Purpose: Agents currently track file_path separately, get generic errors, and have no way to skip fields intentionally. These changes make the API more self-describing and forgiving.
Output: Updated tools_extract.py, tool_errors.py, tools_write.py with ~10 new tests.
</objective>

<execution_context>
@/home/sarturko/.claude/get-shit-done/workflows/execute-plan.md
@/home/sarturko/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-ergonomics-tolerance/09-RESEARCH.md
@src/tools_extract.py
@src/tool_errors.py
@src/tools_write.py
@src/validators.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add file_path echo and write_answers error message</name>
  <files>src/tools_extract.py, src/tool_errors.py, tests/test_ergonomics.py</files>
  <action>
**ERG-01: file_path echo in extract_structure_compact (tools_extract.py)**

In `extract_structure_compact()`, after the if/elif/elif block that calls `model_dump()`, add file_path to the result dict when the input file_path is non-empty. Insert these 2 lines just before the `raise NotImplementedError`:

```python
    if file_path:
        result["file_path"] = file_path
    return result
```

This requires restructuring the function slightly: instead of returning inside each `if ft == ...` block, assign to a `result` variable in each branch, then fall through to the file_path injection and return. If the function already uses early returns, refactor to assign-then-return pattern.

The current code has `return word_extract_compact(raw).model_dump()` etc. Change each to `result = word_extract_compact(raw).model_dump()` (dropping the `return`), then after the three branches add the file_path injection and return. Keep the `raise NotImplementedError` as the else case.

**ERG-02: write_answers error message (tool_errors.py)**

In `resolve_file_for_tool()`, the except block currently raises a generic error. Add a special case BEFORE the generic re-raise:

```python
    except ValueError as exc:
        msg = str(exc)
        if tool_name == "write_answers" and "Neither was supplied" in msg:
            raise ValueError(
                "Missing file_path -- this is the path you passed "
                "to extract_structure_compact"
            ) from exc
        example = USAGE.get(tool_name, tool_name)
        raise ValueError(
            f"{tool_name} error: {exc}\n"
            f"  Example: {example}"
        ) from exc
```

**Tests (tests/test_ergonomics.py)**

Create a new test file. Tests needed:

1. `test_extract_compact_echoes_file_path` -- call extract_structure_compact with a Word fixture via file_path, assert response dict contains `file_path` matching the input path.
2. `test_extract_compact_no_file_path_for_b64` -- call extract_structure_compact with file_bytes_b64 (no file_path), assert `file_path` key is NOT in response dict.
3. `test_extract_compact_echoes_file_path_excel` -- same as test 1 but with Excel fixture.
4. `test_write_answers_missing_file_error_mentions_extract` -- call write_answers with no file_path and no file_bytes_b64, catch ValueError, assert "Missing file_path" and "extract_structure_compact" are in the error message.
5. `test_other_tool_error_does_not_mention_extract` -- call extract_structure_compact with no file input, catch ValueError, assert the error does NOT contain "Missing file_path" (uses generic message).

Use the existing test fixtures from conftest.py (table_questionnaire.docx, vendor_assessment.xlsx).
  </action>
  <verify>Run `python -m pytest tests/test_ergonomics.py -v` and confirm all 5 tests pass. Run `python -m pytest --tb=short` and confirm all 295+ tests pass (no regressions).</verify>
  <done>extract_structure_compact includes file_path in response when file_path input is provided; omits it when using b64. write_answers error for missing file specifically mentions extract_structure_compact. Other tools still show generic error.</done>
</task>

<task type="auto">
  <name>Task 2: Implement SKIP convention and response summary</name>
  <files>src/tools_write.py, tests/test_ergonomics.py</files>
  <action>
**TOL-01 + TOL-02: SKIP detection, filtering, and summary (tools_write.py)**

Add a module-level helper function:

```python
def _is_skip(payload) -> bool:
    """Return True if the answer is an intentional SKIP."""
    return (
        payload.answer_text is not None
        and payload.answer_text.strip().upper() == "SKIP"
    )
```

In `write_answers()`, after `payloads, warnings = build_answer_payloads(...)`, partition payloads:

```python
    skipped = [p for p in payloads if _is_skip(p)]
    to_write = [p for p in payloads if not _is_skip(p)]
```

For the **dry_run** path: modify to show SKIP answers with status="skipped". Before calling `_dry_run_preview`, filter to_write only. Then append skipped entries to the preview:

```python
    if dry_run:
        result = _dry_run_preview(raw, ft, to_write)
        for p in skipped:
            result["preview"].append({
                "pair_id": p.pair_id,
                "xpath": p.xpath,
                "status": "skipped",
                "message": "Intentional SKIP -- field will not be written",
            })
        result["summary"] = {"written": len(to_write), "skipped": len(skipped)}
        return result
```

For the **write** path: if `to_write` is empty (all SKIP), return original file bytes unchanged. Otherwise, pass `to_write` (not `payloads`) to the handler. Build the summary dict and attach to the response:

```python
    if to_write:
        if ft == FileType.WORD:
            result_bytes = word_handler.write_answers(raw, to_write)
        elif ft == FileType.EXCEL:
            result_bytes = excel_handler.write_answers(raw, to_write)
        elif ft == FileType.PDF:
            result_bytes = pdf_handler.write_answers(raw, to_write)
        else:
            raise NotImplementedError(...)
    else:
        result_bytes = raw  # All answers skipped, return original

    summary = {"written": len(to_write), "skipped": len(skipped)}
```

Then in the response-building section (both file_path and b64 branches), add `response["summary"] = summary`. The summary ALWAYS appears, even when skipped count is 0.

**Tests (append to tests/test_ergonomics.py)**

6. `test_skip_answer_not_written` -- provide 3 answers where 1 has answer_text="SKIP". Write to a Word fixture. Verify the SKIP answer is not in the output (extract and check the target cell is still empty).
7. `test_skip_case_insensitive` -- test answer_text="skip" (lowercase) is also recognized as SKIP.
8. `test_all_skip_returns_original` -- provide all-SKIP answers, verify returned bytes are identical to input bytes.
9. `test_summary_always_present` -- provide 2 non-SKIP answers, write, verify response has `summary` with `written: 2, skipped: 0`.
10. `test_summary_with_skips` -- provide 2 non-SKIP + 1 SKIP answer, verify response has `summary` with `written: 2, skipped: 1`.
11. `test_dry_run_shows_skip_status` -- provide 1 real answer + 1 SKIP, dry_run=True, verify the preview includes both: the real one with normal status and the SKIP one with status="skipped".

Use table_questionnaire.docx fixture. For SKIP tests, target different cells (e.g., T1-R2-C2 for a real answer, T1-R3-C2 for a SKIP).
  </action>
  <verify>Run `python -m pytest tests/test_ergonomics.py -v` and confirm all 11 tests pass. Run `python -m pytest --tb=short` and confirm all tests pass (no regressions). Total should be 295 + ~11 = ~306.</verify>
  <done>SKIP answers are filtered before reaching handlers. Response always includes summary with written/skipped counts. dry_run shows SKIP answers with status="skipped". All-SKIP returns unchanged bytes. Case-insensitive SKIP detection works.</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_ergonomics.py -v` -- all ~11 new tests pass
2. `python -m pytest --tb=short` -- all 295+ existing tests pass (no regressions)
3. Success criterion 5 (mode defaults) -- already verified by existing test `test_write_answers_pair_id_only_defaults_mode` from Phase 8
</verification>

<success_criteria>
- extract_structure_compact response includes file_path when provided as input
- write_answers error for missing file says "Missing file_path -- this is the path you passed to extract_structure_compact"
- answer_text="SKIP" (case-insensitive) is recognized: no write, status="skipped"
- write_answers response always includes summary with written and skipped counts
- mode defaults already work (Phase 8) -- no new code needed, confirmed by existing test
- All 295 existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/09-ergonomics-tolerance/09-01-SUMMARY.md`
</output>
